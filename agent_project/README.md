# Agente Experto basado en prompting y MCP usando LangChain y RAG Avanzado

> **Trabajo de Fin de MÃ¡ster (TFM)** - MÃ¡ster Universitario en Inteligencia Artificial (UNIR).

Este proyecto implementa un sistema de **OrquestaciÃ³n de un Agente Experto** capaz de ejecutar procesos de negocio complejos y secuenciales. 
Utiliza una arquitectura hÃ­brida mediante el **Model Context Protocol (MCP)**, coordinando los procesos mediante un Agente en Python y haciendo uso de RAG para obtener el detalle del proceso a ejecutar.

## Resumen de la Arquitectura HÃ­brida

El sistema implementa una arquitectura hÃ­brida porque combina dos ecosistemas tecnolÃ³gicos unidos en una Ãºnica pieza "el orquestador".

### Hibridez Cognitiva (ProbabilÃ­stica + Determinista)
Se fusiona la flexibilidad y comprensiÃ³n del lenguaje de los LLMs con la rigurosidad y fiabilidad de los sistemas de software tradicionales. El LLM es el "operador", pero el cÃ³digo es el "motor".

1. Componente ProbabilÃ­stico (LLM): El Router y el Planner usan IA Generativa. Entienden el lenguaje natural, infieren intenciones y son creativos adaptÃ¡ndose a lo que pide el usuario. Sus respuestas no son 100% fijas (varÃ­an ligeramente).
2. Componente Determinista (CÃ³digo/RAG): El RAG ancla la informaciÃ³n, los documentos determinan categoricamente el proceso que tiene que seguir el LLM sin inventar nada. El CÃ³digo Java/Python ejecuta acciones estrictas: Una base de datos estrictos y, por lo tanto, ejecuta una acciÃ³n mediante MCPs si fuese necesario o da error.

Se define una arquitectura de 3 niveles:
1.  **Nivel Cognitivo (Python + LangGraph):**
    * **Planificador Estricto:** Un nodo especializado lee la documentaciÃ³n (RAG) y genera un plan de ejecuciÃ³n inmutable antes de actuar.
    * **Router SemÃ¡ntico:** Clasifica la intenciÃ³n del usuario para decidir quÃ© manual de procedimientos recuperar.
2.  **Nivel de Memoria (RAG Avanzado):**
    * **Parent Document Retriever:** IndexaciÃ³n hÃ­brida que busca por fragmentos pequeÃ±os (precisiÃ³n) pero recupera documentos completos (contexto), garantizando que el LLM vea todas las fases de un proceso.
    * **Qdrant & Local Store:** Base de datos vectorial para bÃºsqueda semÃ¡ntica combinada con almacenamiento local persistente para los documentos padre.
3.  **Nivel de EjecuciÃ³n (MCP HÃ­brido):**
    * **Herramientas Locales (Stdio):** Python gestiona operaciones de sistema, BBDD y notificaciones.
    * **Herramientas Remotas (SSE):** ConexiÃ³n persistente *Server-Sent Events* con un backend Java Spring Boot para lÃ³gica de negocio crÃ­tica (CRM).


AdemÃ¡s, se puede observar capacidades hÃ­bridas tambiÃ©n en:

1. Hibridez TecnolÃ³gica (PolÃ­glota)
El uso de MCPs nos permite meidante un lenguaje comÃºn comunicar con sistemas escritos en otros lenguajes. Python (El agente experto) se conecta un con una aplicaciÃ³n Java Spring Boot para poder completar uno de los procesos.
2. Hibridez en la EjecuciÃ³n (Local vs. Remoto)
El agente experto tiene la capacidad de leer herramientas de ejecuciÃ³n local (Stdio) y herramientas http (SSE).

---

## ğŸ“‚ Estructura del Proyecto

```text
agent_project/
â”‚
â”œâ”€â”€ doc_store_cache/          # [GENERADO] CachÃ© de documentos padres (Pickle)
â”‚   â””â”€â”€ ... 
â”‚
â”œâ”€â”€ procesos/                 # [FUENTE] Manuales de procedimientos (.md)
â”‚   â”œâ”€â”€ alta_cliente.md
â”‚   â””â”€â”€ baja_cliente.md
â”‚
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ agent/                # LÃ³gica del Agente (Cerebro)
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ agent.py          # Grafo LangGraph
â”‚   â”‚   â”œâ”€â”€ agent_planner.py  # PlanificaciÃ³n del proceso obtenido desde "doc_store_cache"
â”‚   â”‚   â”œâ”€â”€ agent_state.py    # DefiniciÃ³n del Estado (classes)
â”‚   â”‚   â”œâ”€â”€ user_intention.py # Se analiza el input de usuario para identificar que quiere hacer  
â”‚   â”‚   â””â”€â”€ model.py          # ConfiguraciÃ³n LLM (el de vectorizaciÃ³n y el de conversaciÃ³n)
â”‚   â”‚
â”‚   â”œâ”€â”€ mcps/                 # Herramientas MCP
â”‚   â”‚   â”œâ”€â”€ servers/          # DefiniciÃ³n de los servidores en python que tiene salida stdout (consola).
â”‚   â”‚   â”œâ”€â”€ utils/            # DefiniciÃ³n de los logs a fichero
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ mcp_definition.py # Schemas Pydantic de los MPCs (necesario para indicar al agente los parÃ¡metros de los MPCs)
â”‚   â”‚   â”œâ”€â”€ mcp_mapping.py    # Mapeo a LangChain de los MPCs
â”‚   â”‚   â””â”€â”€ mcp_server.py     # Server Stdio (Python) donde se ejecutan los mpcs
â”‚   â”‚
â”‚   â”œâ”€â”€ rag/                  # RAG Avanzado
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ rag_config.py     # Config Qdrant y modelo de embeddings (bge-m3)
â”‚   â”‚   â”œâ”€â”€ rag_engine.py     # DefiniciÃ³n de las funciones principales del rag
â”‚   â”‚   â”œâ”€â”€ rag_index.py      # IndexaciÃ³n de los procesos almacenados en formato .md en la carpeta "procesos" del proyecto
â”‚   â”‚   â””â”€â”€ rag_retrieval.py  # CreaciÃ³n del objeto de bÃºsqueda en el RAG y en doc_store_cache
â”‚   â”‚
â”‚   â”œâ”€â”€ __init__.py
â”‚   â””â”€â”€ main.py               # Orquestador Principal
â”‚
â”œâ”€â”€ .gitignore                # Exclusiones de Git
â”œâ”€â”€ docker-compose.yml        # Infraestructura Qdrant y MongoDB
â”œâ”€â”€ README.md                 # DocumentaciÃ³n
â””â”€â”€ requirements.txt          # Dependencias
```

## ğŸ› ï¸ Requisitos Previos

* **Python:** VersiÃ³n **3.11** (Estricto, necesario para `asyncio.TaskGroup` y no superior).
* **Java:** JDK 17 o superior (Para el servidor MCP CRM que estÃ¡ en el proyecto de java spring).
* **Docker & Docker Compose:** Para levantar la infraestructura de bases de datos.
* **Ollama:** Instalado localmente para ejecutar el modelo de lenguaje.
* **Modelo qwen2.5:32b** Modelo LLM instalado localmente en ollama para su uso por el agente.
* **Modelo bge-m3** Modelo para embeddings instalado localmente en ollama para su uso por el RAG.

---

## ğŸš€ GuÃ­a de InstalaciÃ³n y Puesta en Marcha

Sigue estos pasos en **estricto orden secuencial** para evitar errores de conexiÃ³n.

### 1. instalaciÃ³n de los modelos sobre ollama

```bash
ollama pull qwen2.5:32b
ollama pull bge-m3
```

### 2. InstalaciÃ³n de dependencias
Antes de la instalaciÃ³n recuerda crear un entorno aislado de python para el proyecto (generar la carpeta .venv)
```bash
# En la raÃ­z del proyecto
python3.11 -m venv .venv
source .venv/bin/activate
```
Instalar las dependencias
```bash
# En la raÃ­z del proyecto
pip install -r requirements.txt
```

### 3. Infraestructura Base (Qdrant & MongoDB)
El proyecto incluye un archivo `docker-compose.yml` que orquesta la base de datos vectorial y la documental.

```bash
# En la raÃ­z del proyecto (donde estÃ¡ el docker-compose.yml)
docker-compose up -d
```

### 4. Lanzar Agente
```bash
# En la src del proyecto
python3 main.py
```
